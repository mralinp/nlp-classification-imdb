{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is getting familiar with 'classification' by solving a natural language processing problem that is a kind of **sentimental text processing**. Here we're given some texts in which some users wrote their opinion about a movie. The sentences represent their sentiment about the movie and it says whether they like it or not. we want to process the given sentences and find out that which comment is positive and which one is has a negative opinion about that movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three kinds of datasets are collected. They are testing, training, and validation datasets respectively. We want to build a model and then train our model (here it's a __classifier__) using _Test_ and _Training_ datasets to do the task,  labeling the _Validation_ dataset texts. After all, we will compute the accuracy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are using here is, IMDB dataset (sentiment analysis) in CSV format that you can download it from here: [kaggle.com](https://kaggle.com/columbine/imdb-dataset-sentiment-analysis-in-csv-format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 1, Read the data, Fight!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, as i said before we have to read our datasets from a __.csv__ file that we have been downloaded before from __kaggle__ website.(actuly we have 3 datasets that we have to read)\n",
    "Python has an external library for reading some dataset formats like __csv__ and some other formats called __pandas__.(I love pandas, i mean the animal!)\n",
    "full documentations about how to use and install pandas exists on thier website, you can checkout [here](https://pandas.pydata.org/) to findout how to install and start using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "db = {}\n",
    "db[\"trainDataset\"] = pd.read_csv(\"./data-sets/Train.csv\")\n",
    "db[\"testDataset\"] = pd.read_csv(\"./data-sets/Test.csv\")\n",
    "db[\"validDataset\"] = pd.read_csv(\"./data-sets/Valid.csv\")\n",
    "\n",
    "db[\"trainDataset\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 2, Clean it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first question that comes to my mind is what kind of words or letters are more important? which ones are less?\n",
    "for example, let's look at this sentence:\n",
    "\n",
    "_\" I grew up (n. 1965) watching and loving Thunderbirds, I hate them!\"_\n",
    "\n",
    "Which part can represent the writer's feelings? can you say which parts are more important?\n",
    "It might be a little hard for us to say which parts are more important in a text, beacuse it might depends on writers literature or phychological backgrounds which exists inside writers mind but, here we can surely say the last part _\"i hate them!\"_ representing the exact feeling of the writer about _Thunderbirds_ he *hates them!*. In the other hand, no one will understand any feelings from some kind of punctuations like '(', ''', '.', or even numbers like '1965'. We can omit them to have a better minimal text with fewer extra features.\n",
    "\n",
    "In otherwords we have to clean our data. Some common data cleaning methods are as bellow:\n",
    "\n",
    "**Common data cleaning steps:**\n",
    "* Make text all lower case\n",
    "* Remove punctuation\n",
    "* Remove numerical values\n",
    "* Remove common non-sensical text (/n)\n",
    "* Tokenize text\n",
    "* Remove stop words\n",
    "\n",
    "**More data cleaning steps after tokenization:**\n",
    "* Stemming / lemmatization\n",
    "* Parts of speech tagging\n",
    "* Create bi-grams or tri-grams\n",
    "* Deal with typos\n",
    "* And more...\n",
    "\n",
    "To do so, we have a useful library in python called __regex__ (regular expression library). (Documentations are available [here](https://docs.python.org/3/library/re.html)).\n",
    "\n",
    "In this special case our data has some more extra garbage characters inside it that we want them to be deleted, they are _html tags_ , yes, in this special data sets we are using, there are some html tags that they are embeded inside the comments and we have to first delete them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b9da46146d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def cleanHtmlTags(text):\n",
    "    mask = re.compile(\"<.*?>\")\n",
    "    text = re.sub(mask, \"\", text)\n",
    "    return text\n",
    "\n",
    "for dataset in db.values():\n",
    "    for example in dataset:\n",
    "        print (example)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
